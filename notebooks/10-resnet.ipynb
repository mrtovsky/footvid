{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet\n",
    "\n",
    "This notebook is only a guide on how to fine-tune the **ResNet50** model, because the actual training of the model took place on **Google Colab**, in order to utilize the GPU. For this reason, only some cells have been executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:32:01.264606Z",
     "start_time": "2020-09-22T22:32:00.924516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda available? False.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from footvid.utils.env import check_repository_path\n",
    "\n",
    "\n",
    "REPOSITORY_PATH = check_repository_path()\n",
    "print(\n",
    "    f\"Is cuda available? {torch.cuda.is_available()}.\"\n",
    ")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "N_POS_TRAIN = 1174\n",
    "N_NEG_TRAIN = 893"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Video frames should be prepared according to the previous [01-train-valid-split](https://github.com/mrtovsky/footvid/blob/master/notebooks/01-train-valid-split.ipynb) notebook and the final data **processed** folder structure should look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:32:09.974252Z",
     "start_time": "2020-09-22T22:32:09.827030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../data/processed/\u001b[00m\r\n",
      "├── \u001b[01;34mtrain\u001b[00m\r\n",
      "│   ├── \u001b[01;34mneg\u001b[00m\r\n",
      "│   └── \u001b[01;34mpos\u001b[00m\r\n",
      "└── \u001b[01;34mvalid\u001b[00m\r\n",
      "    ├── \u001b[01;34mneg\u001b[00m\r\n",
      "    └── \u001b[01;34mpos\u001b[00m\r\n",
      "\r\n",
      "6 directories\r\n"
     ]
    }
   ],
   "source": [
    "!tree -d ../data/processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:32:10.480421Z",
     "start_time": "2020-09-22T22:32:10.362131Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "from footvid.preprocessing import TEST_TRANSFORMS, TRAIN_TRANSFORMS\n",
    "\n",
    "\n",
    "\n",
    "train_images = datasets.ImageFolder(\n",
    "    root=REPOSITORY_PATH.joinpath(\"data\", \"processed\", \"train\"),\n",
    "    transform=TRAIN_TRANSFORMS,\n",
    ")\n",
    "\n",
    "valid_images = datasets.ImageFolder(\n",
    "    root=REPOSITORY_PATH.joinpath(\"data\", \"processed\", \"valid\"),\n",
    "    transform=TEST_TRANSFORMS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check which index is corresponding to which class. It's good to know what is being modeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:32:26.929357Z",
     "start_time": "2020-09-22T22:32:26.925322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  {'neg': 0, 'pos': 1}\n",
      "Valid:  {'neg': 0, 'pos': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \", train_images.class_to_idx)\n",
    "print(\"Valid: \", valid_images.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:32:27.478131Z",
     "start_time": "2020-09-22T22:32:27.474293Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_images,  batch_size=64, shuffle=True, num_workers=2\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    dataset=valid_images,  batch_size=64, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "**PyTorch** native implementation of the **ResNet50** has been slightly modified to meet the requirements of the problem posed. The size of the output has been changed to match the binary classification problem and a hook has been added after the convolution layers which will definitely facilitate the visualization of **Grad-CAM**. The pre-trained weights remained unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:32:28.897069Z",
     "start_time": "2020-09-22T22:32:28.333438Z"
    }
   },
   "outputs": [],
   "source": [
    "from footvid.models import ResNet\n",
    "\n",
    "\n",
    "model = ResNet(output_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning\n",
    "\n",
    "Drawing inspiration from [Karpathy et al.](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf) we want to test model fine-tuning in three variants:\n",
    "- fine-tune fully-connected layer only,\n",
    "- fine-tune top2 CNN layers as well as the FCL,\n",
    "- fine-tune all layers.\n",
    "\n",
    "Function [footvid.arena.freeze_layers](https://github.com/mrtovsky/footvid/blob/master/footvid/arena.py#L20) will come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:32:30.277331Z",
     "start_time": "2020-09-22T22:32:29.869402Z"
    }
   },
   "outputs": [],
   "source": [
    "from footvid.arena import freeze_layers\n",
    "\n",
    "\n",
    "model_fcl = freeze_layers(model, last_layer=\"avgpool\", inplace=False)\n",
    "model_fcl = model_fcl.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T22:31:49.867331Z",
     "start_time": "2020-09-22T22:31:40.505788Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from footvid.arena import run_experiment, TrainTestDataloaders\n",
    "\n",
    "\n",
    "artifacts_dir = REPOSITORY_PATH.joinpath(\"models\", \"fcl-resnet-fine-tuning\")\n",
    "artifacts_dir.mkdir(exist_ok=True)\n",
    "optimizer = optim.SGD(model_fcl.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10], gamma=0.1)\n",
    "objective = nn.BCEWithLogitsLoss()\n",
    "train_test_dataloaders = TrainTestDataloaders(train=train_dataloader, test=valid_dataloader)\n",
    "writer = SummaryWriter(log_dir=REPOSITORY_PATH.joinpath(\"logs\", \"fcl-resnet-fine-tuning\"))\n",
    "\n",
    "run_experiment(\n",
    "    model=model_fcl,\n",
    "    dataloaders=train_test_dataloaders,\n",
    "    device=DEVICE,\n",
    "    optimizer=optimizer,\n",
    "    objective=objective,\n",
    "    epochs=20,\n",
    "    threshold=N_POS_TRAIN / (N_POS_TRAIN + N_NEG_TRAIN),\n",
    "    scheduler=scheduler,\n",
    "    artifacts_dir=artifacts_dir,\n",
    "    writer=writer,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "footvid-venv",
   "language": "python",
   "name": "footvid-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
